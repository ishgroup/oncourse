Willow Search
=============

Purpose
-------
The search mechanism in Willow is primarily designed to search for matching courses and display them  in the list view. It may be that it is useful for searching and returning other lists (eg tutors) but those other purposes are secondary.

Search criteria
---------------
1. Course name
2. Course description
3. Course code (eg. ABC)
4. Course-class code (eg. ABC-123)
5. Tutor name (first and last)
6. Distance from postcode or suburb
7. Price (always expressed as a 'less than x' or 'between x and y')
8. Day of week (possibly per day, but usually divided into weekday and weekend)
9. Time of day (divided only into day/evening, as starttime before 5pm or after)
10. Tag

Note that the items in the above list will require the indexing of data from Course, CourseClass, Room, Site, Tutor and Session. But the results are always a list of courses which are then displayed. In the case of to-many tables like Session, it may be that a course has a class with only one evening session which causes it to match filter 9, but another dozen sessions which do not. That is OK. Most classes are scheduled in fairly uniform ways, so excessive effort is not required to produce perfect results.

-- Solution
Use DataImportHandler and JDBC for importing and indexing content from database. Combine data from  Course, CourseClass, Room, Site, Tutor and Session into one document with SQL-joins or solr inner entities. http://wiki.apache.org/solr/DataImportHandler



  Searching on text fields needs to be flexible enough to allow for 'contains in' or 'starts with' searches. For example, when typing a suburb name, course code or course-class code only simple 'starts with' searches are required. When searching on course name or description, a contains in search will be required which also incorporates word stemming and thesaurus operations.

-- Solution
  Stemming: there are a few options  http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#Stemming. Thesaurus operations: http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#solr.SynonymFilterFactory

Distance
--------
The user is allowed to type a suburb name in order to get a typeahead dropdown of suburbs (see http://www.sydneycommunitycollege.com.au in the top right search and try "glebe"). We already restrict the search to a certain state (in which the college is located) to avoid pulling in too many choices. For example, there is a Glebe in NSW and one in TAS but only the NSW one is shown.

We already have the latitude and longitude of the centre of every postcode in Australia in an existing database. These pages seem relevant.

https://issues.apache.org/jira/browse/SOLR-773
http://www.nsshutdown.com/projects/lucene/whitepaper/locallucene_v2.html

-- Solution
  Use function queries with Solr's distance functions. Extract and save in index Site suburb GeoLocation. http://wiki.apache.org/solr/SpatialSearch. http://www.ibm.com/developerworks/opensource/library/j-spatial/index.html 


Types of search results
-----------------------
1. Search results as displayed in a list of courses
2. Type-ahead (clairvoyance) displayed as a drop down in a search box.

Prototype
---------
Consult the Sydney Community College web site as an example for how type-ahead should work (notice that you can type in suburb names as well as course title and tags). Type "bus" and "glebe" for examples of these. Also consult that site for the advanced search dialog and results page.

-- Solution
  For #1 search use solj SolrServer interface either CommonsHttpSolrServer or EmbeddedSolrServer. For type-ahead: Using EdgeNGrams http://www.lucidimagination.com/blog/2009/09/08/auto-suggest-from-popular-queries-using-edgengrams/                                                                                                                    http://wiki.apache.org/solr/TermsComponent with jquery.autocomplete using JSONP or xml response parsing by JavaScript. http://docs.jquery.com/Plugins/Autocomplete


Sorting
-------
A key difference to the existing search results (which are always sorted alphabetically) is that we require weighted search results. For example, matches in the course name will be sorted higher than word stem matches in the course description. The ability to adjust these weightings and tweak them over time (without recompiling code) is essential.

Sometimes it will be easy to separate 'good results' from 'partial matches', probably by weighting score. This is already implemented on the existing site:

  http://www.sydneycommunitycollege.com.au/courses?price=100&day=weekday&s=bus

Notice the divider half way down that page.

-- Solution
  The scores of documents fields can be increased/decreased by specific query params as described here: http://wiki.apache.org/solr/SolrRelevancyFAQ http://wiki.apache.org/solr/CommonQueryParameters


Other entities
--------------
It is likely that we will want to index and search on web pages in the future. This should be allowed for, but right now it is not required since it is not obvious how to mix the search results of web pages with the list of courses and still keep a clean UI.

-- Solution
  No problem with Sorl, creating separate entity and using appropriate Filter.

URLs
----
Clean URLs are required since bookmarking and linking to search results is important.

-- Solution
  Resolved on by UrlMapper on Tapestry weblayer.

Pagination
----------
Implemented as per the existing site: that is, no page numbers but just a 'more' link at the bottom which adds further results to the existing page.

-- Solution
  Paging archieved by default Solr queries parameters "start" and "rows". http://wiki.apache.org/solr/CommonQueryParameters

Speed
-----
Results for the type-ahead need to be generated to the user in under 0.5 second for a system under load. For the search results page, response within 3 seconds is acceptable, 1 second good (not including data transfer and page drawing). Search is an important page of these sites.

-- Solution
  Many options to tune JVM configuration, HTTP and Solr caches, http://wiki.apache.org/solr/SolrCaching

Production environment
----------------------
It is essential that this service be reliable. If an external service is to be used (such as Solr) then consideration about how to create a cluster of services needs to be had. If the service is embedded and the index local, then consideration about how to synchronise this index between application servers is important (rsync?).

-- Solution
  Scaling Solr horizontally with Maser-Slave replication between nodes and load balance search requests. (http://wiki.apache.org/solr/SolrReplication http://www.lucidimagination.com/Community/Hear-from-the-Experts/Articles/Scaling-Lucene-and-Solr) or using Index sharding http://wiki.apache.org/solr/DistributedSearch, http://wiki.apache.org/solr/KattaIntegration, http://wiki.apache.org/solr/ZooKeeperIntegration. Combination of both aproaches can be used as well.


Another important factor is investigating how we will be writing the index. Updating of the relevant data happens through the Willow services application, so it could be in charge of adding objects to the index or to a queue for periodic indexing. It is not important that the index be completely up to date, but within 30 minutes would be nice and no more than 60 minutes essential.

-- Solution
  Solr delta-import command. Use SQL to locate modified entities by timestamp. Requires HTTP GET to http://localhost:8983/solr/dataimport?command=delta-import to spawn index update. We can use either cron job which makes HTTP GET or callback in Cayenne for instantly triggered update or other notification mechanism (Cayenne callback JMS) depending on which infrastructure components is already in place.